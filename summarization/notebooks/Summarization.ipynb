{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d984c3d-7996-4b6f-a200-ed3675e65880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain boto3\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0fc4e-4a05-4ccf-81c6-02736822367e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install langchain==0.0.224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8451b-7e59-4e50-b4b3-a85dc5387120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc1f81-0556-4ab3-af81-88fdc18c3d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint, LLMChain\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac741a-d89f-432d-be9e-2caca4bdc429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2bfee691-1a60-48f5-b657-dc26242315d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "llm2 = SagemakerEndpoint(\n",
    "endpoint_name=\"hf-llm-falcon-40b-instruct-bf16-2023-06-23-19-34-33-102\",\n",
    "#endpoint_name=\"hf-llm-falcon-7b-bf16-2023-06-24-20-08-14-262\",\n",
    "#endpoint_name=\"hf-llm-falcon-40b-bf16-2023-06-24-20-20-44-608\",\n",
    "model_kwargs={\n",
    "     \"parameters\" : {\"do_sample\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_new_tokens\": 200\n",
    "              }},\n",
    "region_name=\"us-east-1\",\n",
    "content_handler=content_handler\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 4000,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f072c40c-2487-45ef-86a1-29cb102e6f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"bots.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9c159019-2f02-4bec-8c2e-f2d21f3d044a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='May 13th, Friday presentation to Athena\\n* Vijay: AMI refresh requirement makes instance storage difficult as the hydrating of cassandra nodes from backup takes too long\\n* Habib wants a dedicated session to affirmatively answer if EBS bandwidth is/is not the cause of slowness.\\n* 35GBps is the aggregate ec2 network output. a fraction of that is cross region (unknown - asked Mayur to check with GNS). 40GBps is close to the Denali Stamp limit. they got a dedicated stamp in last 2 months and have not seen the issue since.\\n\\nMay 11th  - Summary for Athena team - (Hari, Ruchir, Shamik)\\nBased on the assessment and prior discussions Athena’s key resiliency considerations fall under Observability, Operations, Testing.\\n\\n1. Do you have observability alerts in-place to detect network failure and ability for Athena to take action based on those alerts ?\\n2. In the event of network connection failure between us-east-1 and us-west-2 what is the current application behavior ?\\n3. You mentioned it takes upto 6 hrs for data to be in sync, in the event of network connection failure between us-east-1 and us-west-2. Why does it take 6 hours ? How often has such a failure occurred in last 3, 6, 9 and 12 months ?\\n4. In the event of network connection failure between us-east-1 and us-west-2, what is more important for the business -  consistency amongst the Cassandra nodes or the availability of the nodes ?\\n5. What is the observed EBS disk queue length ?\\n6. In scenarios of large # of nodes and >300 EBS volumes, everyday some of the EBS volumes might see slowness. Is this tolerable, and have you considered using instance storage (e.g. i3, m5d instances)\\n7. What is the volume and velocity of data synced by cassandra and compute layer across regions in normal scenarios ?\\n8. At what event do you typically restore from backups? What are the dependencies and events that you consider for taking backups ? How often are the backups taken ?\\n9. Could you tell us the type of compute instances (m5.8xlarge??) on which Cassandra nodes (EC2) is running? and the type of EBS volumes currently leveraged (gp2, gp3, io1, io2, sc1, st1)? Are they backed by SSDs? or HDDs?\\n    1. Instance store vs EBS volumes - speed vs backups vs price;\\n10. Cellular Architecture - “One of the bedrock principles for service design in AWS is the avoidance of single points of failure in underlying physical infrastructure…Similarly, systems are built to be resilient to failure of a single compute node, single storage volume, or single instance of a database….it’s important to ensure that the components operate independently. The benefits achieved from theoretical availability calculations with redundant components are only valid if this holds true.”\\n    1. Thinking longer term towards a much more resilient architecture with sufficient isolations built-in - currently the arch. is broken down by AODC and AWS with bidirectional replication within those. How about visualizing into 4 different cells (by AODC and AWS regions) with replication amongst 4 so we make the architecture more scalable and resilient?\\n    2. Data partitioning strategy - Have you considered partitioning into disjoint sets?\\n    3. In the event of a massive DDOS attack how do we limit the blast radius in the current architecture?\\n    4. How autonomous is each region in the underlying architecture?' metadata={}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "for x in docs:\n",
    "    print(x)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "30906ed7-348f-4b11-ac17-41a20c6e79f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_prompt_template = \"\"\"Write a short sentence single line summary for following text:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "\n",
    "reduce_prompt_template = \"\"\"Write a summary paragraph of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "Summary:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "418c4eba-0d03-447e-ab9b-ca8c66fe07ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['\\n\\nThe summary for the given text is as follows:\\n\\n1. The presentation to Athena team discusses the key resiliency considerations for Athena, including observability, operations, and testing.\\n2. The team asks questions about the current application behavior in the event of network connection failure between us-east-1 and us-west-2, the time it takes for data to be in sync, and the importance of consistency or availability of nodes.\\n3. The team also asks about the observed EBS disk queue length, the tolerability of slowness in large volumes of EBS, and the use of instance storage.\\n4. The team inquires about the volume and velocity of data synced by cassandra and compute layer across regions in normal scenarios, the event of restoring from backups, and the dependencies and events considered for taking backups.\\n5. The team asks about the type of compute instances and EBS volumes currently leveraged, and the type of backups and price.'],\n",
       " 'output_text': '\\nThe presentation to Athena team discusses the key resiliency considerations for Athena, including observability, operations, and testing. The team asks questions about the current application behavior in the event of network connection failure between us-east-1 and us-west-2, the time it takes for data to be in sync, and the importance of consistency or availability of nodes. The team also asks about the observed EBS disk queue length, the tolerability of slowness in large volumes of EBS, and the use of instance storage. The team inquires about the volume and velocity of data synced by cassandra and compute layer across regions in normal scenarios, the event of restoring from backups, and the dependencies and events considered for taking backups. The team asks about the type of compute instances and EBS volumes currently leveraged, and the type of backups and price.'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "MAP_PROMPT = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "REDUCE_PROMPT = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "\n",
    "chain = load_summarize_chain(llm2, chain_type=\"map_reduce\", return_intermediate_steps=True, map_prompt=MAP_PROMPT,  combine_prompt=REDUCE_PROMPT)\n",
    "#chain.run(docs)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9754397-9e89-4831-a018-aedb4aac439f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b06c8-9222-4a75-a817-bcc9148e60e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4f900-8c00-4fad-af5c-553254ac71a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
