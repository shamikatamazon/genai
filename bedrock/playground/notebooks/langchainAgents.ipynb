{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0cec85-d63c-4b86-ad7b-c6e97f1c1d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain boto3\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47bb0c-cbd7-49e0-92df-01d417231d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168faab2-a433-4196-bb7f-64b4e41c624f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dc28e-1957-4320-88ac-7f4b3231c94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ~/SageMaker/botocore-1.29.162-py3-none-any.whl\n",
    "!pip install ~/SageMaker/boto3-1.26.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e24c9-2a72-4c14-878d-ed7e82f86116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bf28c-7f53-4dfe-acb9-17e1015b10de",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Deploy Falcon/Llama model as a Sagemaker Endpoint prior to running this example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728fa95-055c-42dd-941e-4dfef5256b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import langchain\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain import SagemakerEndpoint, LLMChain\n",
    "from langchain import LLMChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811f373-fdc7-4f7a-af5f-23eac6511f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80373bb-52b3-481f-a5e4-39702610727f",
   "metadata": {},
   "source": [
    "### Create the tools\n",
    "\n",
    "We create the \"tools\" which will be executed by agent. In this example we create 3 tools, one for addition, another for subtraction and one for generating a random number. The input into this tool is a string in the format \"x,y\" for the addition/subtraction functions and a single number for the random number generator. Note that the inputs are strings and hence we can use a split function. This works for a simplistic example, but ideally the LLM should respond with a JSON object which can be parsed by this tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10047f-3803-4216-9c8f-457d3a8dec2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import BaseTool\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "def addTwoNumbers(numberList: str) -> str:\n",
    "    print(\"\\nthe add numbers tools executed\\n\")\n",
    "    x = numberList.split(\",\")\n",
    "    answer = int(x[0]) + int(x[1])\n",
    "    return \"The sum is \" + str(answer)\n",
    "\n",
    "def subtractTwoNumbers(numberList):\n",
    "    print(\"\\nthe subtract numbers tools executed\\n\")\n",
    "    x = numberList.split(\",\")\n",
    "    answer = int(x[0]) - int(x[1])\n",
    "    return \"The difference is \" + str(answer)\n",
    "\n",
    "\n",
    "def generateRandomNumber(aNumber):\n",
    "    #print(aNumber)\n",
    "    print(\"\\nthe random number tool executed\\n\")\n",
    "    return \"A random number is \" + str(random.randint(0,int(aNumber)))\n",
    "\n",
    "random_number_tool = Tool(\n",
    "    name=\"RandomNumberTool\",\n",
    "    func = generateRandomNumber,\n",
    "    description=\"a tool to generate random numbers\"\n",
    ")\n",
    "\n",
    "addition_tool = Tool(\n",
    "    name=\"AdditionTool\",\n",
    "    func = addTwoNumbers,\n",
    "    description=\"a tool to add two numbers\"\n",
    ")\n",
    "\n",
    "subtraction_tool = Tool(\n",
    "    name=\"SubtractionTool\",\n",
    "    func = subtractTwoNumbers,\n",
    "    description=\"a tool to get the difference between two numbers\"\n",
    ")\n",
    "\n",
    "tools = [random_number_tool, addition_tool, subtraction_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7eabdb-f87e-4aaa-8737-d9f2de3b5ce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The ReAct prompt\n",
    "\n",
    "A prompt template is created for the few-shot-learning example. The prompts are in the format Human/Thought/Action/Action Input/Observation/Action. \n",
    "\n",
    "The Action Input: in the prompt is used to pass parameters to the tools and is optional if the tool doesn't require any input parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de4a04-ea58-406f-bbf0-04a45681eca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "falcon_template = \"\"\"Human: Answer the following questions as best you can. Do not use your random number generator, always use the tools. If the human asks a question that can't be solved by a tool, say \"no tool available\". You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Human: Generate a number between 0 and 100 \\n Thought: I need to use a tool to generate a random number with a maximum of 100 \\n Action: RandomNumberTool() \\n Action Input: 100 \\n Observation: A random number is 6 \\n Thought: I have a random number \\n Action: Finish[6] \n",
    "Human: Generate a number between 0 and 100000 \\n Thought: I need to use a tool to generate a random number with a maximum of 100000 \\n Action: RandomNumberTool() \\n Action Input: 100000 \\n Observation: A random number is 6 \\n Thought: I have a random number \\n Action: Finish[6] \n",
    "Human: Give me a random number with a maximum of 45 \\n Thought: I need to use a tool to generate a random number with a maximum of 45 \\n Action: RandomNumberTool() \\n Action Input: 45 \\n Observation: A random number is 9 \\n Thought: I have a random number \\n Action: Finish[9] \n",
    "Human: Add the numbers 10 and 5 \\n Thought: I need to use a tool to add two numbers 10 and 5 \\n Action: AdditionTool() \\n Action Input: 10,5 \\n Observation: the sum is 15 \\n Thought: I have the sum \\n Action: Finish[15] \n",
    "Human: Combine the numbers 10 and 5 \\n Thought: I need to use a tool to add two numbers 10 and 5 \\n Action: AdditionTool() \\n Action Input: 10,5 \\n Observation: the sum is 55 \\n Thought: I have the sum \\n Action: Finish[15] \n",
    "Human: Subtract the numbers 10 and 5 \\n Thought: I need to use a tool to subtract two numbers 10 and 5 \\n Action: SubtractionTool() \\n Action Input: 10,5 \\n Observation: the difference is 5 \\n Thought: I have the difference \\n Action: Finish[5] \n",
    "Human: get the difference between 10 and 5 \\n Thought: I need to use a tool to subtract two numbers 10 and 5 \\n Action: SubtractionTool() \\n Action Input: 10,5 \\n Observation: the difference is 5 \\n Thought: I have the difference \\n Action: Finish[5] \n",
    "Human: get the difference between 10 and 15 \\n Thought: I need to use a tool to subtract two numbers 10 and 15 \\n Action: SubtractionTool() \\n Action Input: 10,15 \\n Observation: the difference is -5 \\n Thought: I have the difference \\n Action: Finish[-5] \n",
    "Human: get the difference \\n \\n Thought: I need to use a tool to subtract two numbers \\n Action: SubtractionTool() \\n Action Input: none \\n Observation: the difference is 0 \\n Thought: I have the difference \\n Action: Finish[0] \n",
    "Human: get the difference \\n \\n Thought: I need to use a tool to add two numbers \\n Action: AdditionTool() \\n Action Input: none \\n Observation: the sum is 0 \\n Thought: I have the sum \\n Action: Finish[0] \n",
    "Human: get the difference of 9 \\n \\n Thought: I need to use a tool to subtract two numbers \\n Action: SubtractionTool() \\n Action Input: none \\n Observation: the difference is 0 \\n Thought: I have the difference \\n Action: Finish[0] \n",
    "Human: get the sum of 10 \\n \\n Thought: I need to use a tool to add two numbers \\n Action: AdditionTool() \\n Action Input: none \\n Observation: the sum is 0 \\n Thought: I have the sum \\n Action: Finish[0] \n",
    "\n",
    "Human: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444611a2-1d9e-4bd6-b66d-d7d7c15dd4f9",
   "metadata": {},
   "source": [
    "### The Prompt Template\n",
    "\n",
    "Define a prompt template that wraps the prompt and injects the input and tools into the prompt that is fed to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae89d4-438a-404d-bb5e-1c2ce4f5838b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        #tools = self.tools_getter(kwargs[\"input\"])\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        #kwargs[\"tools\"] = \"\\n\".join(\n",
    "        #    [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        #)\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "falcon_prompt = CustomPromptTemplate(\n",
    "    template=falcon_template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30be9f9-c2fa-432b-9a29-d39c5682ee69",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "The agent invokes the Output parser once it receives a response from the LLM. The Output parser is responsible for examining the output and determining the tool to use and the parameters to send to the tool. In the implementation below, we use regex to extract the Action and Action Inputs. An instance of AgentAction is returned that contains the tool to be executed and the parameters for the tool. In the case where the agent has completed execution, an AgentFinish object is returned to the Agent. \n",
    "\n",
    "Note that since regex is being used, there is tight coupling between the prompt template and agent action/action input and any change in the prompts for the Action and Action Input should be reflected in this class. Its important to set the temperature=0 to ensure that the model only returns the outputs that are expected in the Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ec5dc-9603-4ee8-b832-c92f83196e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Finish\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Finish\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        #regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        regex=r\"Action:\\s([a-zA-Z]*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        #print(\"the action is\")\n",
    "        #print(action)\n",
    "        \n",
    "        tool_input= \"\"\n",
    "        \n",
    "        match action:\n",
    "            case \"RandomNumberTool\" :\n",
    "                #Input:\\s([0-9]*)\n",
    "                funcParameterRegex = r\"Input:\\s([0-9]*)\"\n",
    "                funcMatch = re.search(funcParameterRegex, llm_output, re.DOTALL)\n",
    "                if not funcMatch:\n",
    "                    parameter = 100\n",
    "                else:\n",
    "                    parameter = funcMatch.group(1).strip()\n",
    "                #print(\"func parameter is\")\n",
    "                #print(parameter)\n",
    "                tool_input = parameter\n",
    "\n",
    "            case \"AdditionTool\":\n",
    "                #Input:\\s([0-9]*)\\,([0-9]*)\n",
    "                addParamsRegex = r\"Input:\\s([0-9]*)\\,([0-9]*)\"\n",
    "                addMatch = re.search(addParamsRegex, llm_output, re.DOTALL)\n",
    "                parameter = []\n",
    "                if not addMatch:\n",
    "                    tool_input = \"0,0\"\n",
    "                else:\n",
    "                    tool_input = addMatch.group(1).strip() + \",\" + addMatch.group(2).strip()\n",
    "                \n",
    "            \n",
    "            case \"SubtractionTool\":\n",
    "                #Input:\\s([0-9]*)\\,([0-9]*)\n",
    "                addParamsRegex = r\"Input:\\s([0-9]*)\\,([0-9]*)\"\n",
    "                addMatch = re.search(addParamsRegex, llm_output, re.DOTALL)\n",
    "                if not addMatch:\n",
    "                    tool_input = \"0,0\"\n",
    "                else:\n",
    "                    tool_input = addMatch.group(1).strip() + \",\" + addMatch.group(2).strip()\n",
    "\n",
    "        #action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        #action = action + \"Tool\"\n",
    "        #print (action)\n",
    "        return AgentAction(\n",
    "            #tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "            tool=action, tool_input=tool_input, log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf6e62-3881-4299-94c7-6b84fbbebd21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be9f0c-eedd-47f0-ad91-7c5af245b210",
   "metadata": {},
   "source": [
    "### Content Handlers\n",
    "\n",
    "Content Handlers are defined to convert the input to the input expected by the model and to extract the response from the JSON returned by the model. Note that the LlamaContentHandler extracts the response from ```response_json[0][\"generation\"]``` while the ContentHandler (used by Falcon) extracts the response from ```return response_json[0][\"generated_text\"]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215b923-c2e1-40d4-be48-07f1f2d57136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b31f4-72fd-4a25-af69-3871ecc6e8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlamaContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generation\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "llama_content_handler = LlamaContentHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f7a1e-6118-4d33-a0d2-3846e02ce948",
   "metadata": {},
   "source": [
    "### Define the LLMs\n",
    "\n",
    "We define the LLMs that we want to use for predictions. Ensure that you change the ```endpoint_name``` and ```region``` to point to your own Sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb06c-484c-4a26-9822-25ddedb65768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_falcon = SagemakerEndpoint(\n",
    "endpoint_name=\"hf-llm-falcon-40b-bf16-2023-06-24-20-20-44-608\",\n",
    "model_kwargs={\n",
    "     \"parameters\" : {\"do_sample\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_new_tokens\": 40\n",
    "              }},\n",
    "region_name=\"us-east-1\",\n",
    "content_handler=content_handler\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_llama = SagemakerEndpoint(\n",
    "endpoint_name=\"jumpstart-dft-meta-textgeneration-llama-2-7b\",\n",
    "model_kwargs={\n",
    "     \"parameters\" : {\"return_full_text\": False,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_new_tokens\": 40\n",
    "              }},\n",
    "endpoint_kwargs={\"CustomAttributes\": \"accept_eula=true\"},\n",
    "region_name=\"us-east-1\",\n",
    "content_handler=llama_content_handler\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bed45-36ed-460b-a461-e0ae942b7b72",
   "metadata": {},
   "source": [
    "### Define the LLM Chain\n",
    "\n",
    "The LLM chain is defined and we provide the LLM that we want to use along with the PromptTemplate that we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03328d35-fc62-451b-a833-1fbfcf1721e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm_llama, prompt=falcon_prompt)\n",
    "#falcon_llm_chain = LLMChain(llm=llm_falcon, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e856420-370d-4b3d-a361-449602988e8a",
   "metadata": {},
   "source": [
    "### Define and create the Agent\n",
    "\n",
    "In this implementation we use the LLMSingleActionAgent (https://js.langchain.com/docs/api/agents/classes/LLMSingleActionAgent) as this is a simplistic tool that generates an output in a single action, i.e. Add 2 numbers gives an deterministic answer right away. However, if your agents are more sophisticated and require multiple calls to the tool to derive an answer, you can choose to use another agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509193b4-6daa-440d-8797-a3037db916e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    #llm_chain=llm_chain,\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nHuman:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a057a89-00af-4e98-b503-80f30a0cfdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1506337-79b8-4dd9-9491-42a958f65b82",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Now that we have defined the tools, the prompts and the agent, we can perform an inference. When you run the block below you should see an output like \n",
    "\n",
    "```\n",
    "> Entering new  chain...\n",
    " Thought: I need to use a tool to add two numbers \n",
    " Action: AdditionTool() \n",
    " Action Input: 10,36 \n",
    " Observation: the sum is\n",
    "the add numbers tools executed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Human:The sum is 46\n",
    "\n",
    "Action: Finish[46]\n",
    "\n",
    "> Finished chain.\n",
    "'[46]'\n",
    "```\n",
    "\n",
    "A debug statement in the tool ```the add numbers tools executed``` confirms that the tool was invoked and used to derive the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733722b-7cc1-413e-84e2-ea4b20666fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain.debug = False\n",
    "agent_executor.run(\"sum of 10 and 36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21edba-2852-4d15-9e83-a1a0410c2342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor.run(\"get the difference between 500 and 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19553cd-0c64-485b-ad7e-ad6f30e51136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langchain.debug = False\n",
    "agent_executor.run(\"Generate a number between 0 and 500000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51f3ac-59f6-4e93-9409-36ccbb14b934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
