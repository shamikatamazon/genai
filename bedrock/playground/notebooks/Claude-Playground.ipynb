{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d984c3d-7996-4b6f-a200-ed3675e65880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain boto3\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0fc4e-4a05-4ccf-81c6-02736822367e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install langchain==0.0.224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8451b-7e59-4e50-b4b3-a85dc5387120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cf040-3b47-45dc-9792-e9d3d3238bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ~/SageMaker/botocore-1.29.162-py3-none-any.whl\n",
    "!pip install ~/SageMaker/boto3-1.26.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc1f81-0556-4ab3-af81-88fdc18c3d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain import SagemakerEndpoint, LLMChain\n",
    "from langchain import LLMChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac741a-d89f-432d-be9e-2caca4bdc429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfee691-1a60-48f5-b657-dc26242315d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#llm2 = Bedrock(\n",
    "#model_id=\"anthropic.claude-v1\",\n",
    "#model_kwargs={'max_tokens_to_sample': 300})\n",
    "\n",
    "maxTokensToSample = 300\n",
    "temp = 0.6\n",
    "topP = 0.9\n",
    "\n",
    "\n",
    "#modelArgs = {'maxTokens': int(maxTokensToSample), 'temperature':float(temp), \"topP\": float(topP),\"stop_sequences\":[]}\n",
    "modelArgs = {'maxTokens': int(maxTokensToSample) , 'temperature':float(temp), \"topP\": float(topP)}\n",
    "\n",
    "llm2 = Bedrock(\n",
    "model_id=\"ai21.j2-jumbo-instruct\",\n",
    "model_kwargs=modelArgs)\n",
    "\n",
    "#llm2.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9754397-9e89-4831-a018-aedb4aac439f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_query= \"my airpods are not connecting to the iphone, how do I fix that \"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "  {context}\n",
    "    {question}\n",
    "  \"\"\"\n",
    "  \n",
    "PROMPT = PromptTemplate(\n",
    "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "  )\n",
    "  \n",
    "chain = load_qa_chain(llm=llm2, prompt=PROMPT, verbose=True)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b06c8-9222-4a75-a817-bcc9148e60e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chain({\"input_documents\":\"\", \"question\": llm_query}, return_only_outputs=False)\n",
    "print(output['output_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4f900-8c00-4fad-af5c-553254ac71a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
