{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c7387-a9d2-4546-bed6-ae2b8ec3c100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain boto3\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736e7d2-cc55-415d-a583-426355b853fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install langchain==0.0.224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8111454-efac-4555-93d4-50f12642f1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a73dc3-c88f-4fc4-b857-21898fd5a007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ~/SageMaker/botocore-1.29.162-py3-none-any.whl\n",
    "!pip install ~/SageMaker/boto3-1.26.162-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66cb0a-d4ab-4ad3-9a65-90181b171e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f9d17-fd14-410f-88d6-c8781e79dca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a582a36-00f4-4b25-a9ec-d42468dafdbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain import SagemakerEndpoint, LLMChain\n",
    "from langchain import LLMChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983f9f3-3a8d-4595-b683-ae8d7d5d745f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "#        return response_json[\"vectors\"]\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54c835-3c58-492a-bcd7-b48a34156b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#llm2 = Bedrock(\n",
    "#model_id=\"anthropic.claude-v1\",\n",
    "#model_kwargs={'max_tokens_to_sample': 300})\n",
    "\n",
    "maxTokensToSample = 300\n",
    "temp = 0.6\n",
    "topP = 0.9\n",
    "topK= 5\n",
    "\n",
    "modelArgs = {'max_tokens_to_sample': int(maxTokensToSample), 'temperature':float(temp), \"top_k\":int(topK),\"top_p\": float(topP),\"stop_sequences\":[]}\n",
    "#modelArgs = {'maxTokens': int(maxTokensToSample), 'temperature':float(temp), \"topP\": float(topP),\"stop_sequences\":[]}\n",
    "#modelArgs = {'maxTokens': int(maxTokensToSample) , 'temperature':float(temp), \"topP\": float(topP)}\n",
    "\n",
    "llm2 = Bedrock(\n",
    "model_id=\"anthropic.claude-v1\",\n",
    "model_kwargs=modelArgs)\n",
    "\n",
    "#llm2.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0dd6c0-dda4-4421-8cbe-e5be89f5f383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Document2.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abfdbd-6810-474d-9a74-36fba18a86a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e569cc-edd8-451f-9bde-746fa9d59359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages, BedrockEmbeddings())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a13b7-ff01-467f-9242-3887a97a2ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_query= \"how do we bake cookies ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba58291-d1d6-433b-bc74-0facbec41a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = faiss_index.similarity_search(llm_query, k=5)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374a335-d817-463b-aa14-21783e1abe58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Human:{context} {question}\n",
    "Assistant: \n",
    "  \"\"\"\n",
    "  \n",
    "PROMPT = PromptTemplate(\n",
    "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "  )\n",
    "  \n",
    "chain = load_qa_chain(llm=llm2, prompt=PROMPT, verbose=True)\n",
    "output = chain({\"input_documents\":docs, \"question\": llm_query}, return_only_outputs=False)\n",
    "print(output['output_text'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14b944-ff25-49ab-82c7-e7268bac1430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
